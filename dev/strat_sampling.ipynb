{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ashwindesilva/research/ood-tl')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datahandlers.cifar import SplitCIFARHandler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wif(id):\n",
    "    \"\"\"\n",
    "    Used to fix randomization bug for pytorch dataloader + numpy\n",
    "    Code from https://github.com/pytorch/pytorch/issues/5059\n",
    "    \"\"\"\n",
    "    process_seed = torch.initial_seed()\n",
    "    # Back out the base_seed so we can use all the bits.\n",
    "    base_seed = process_seed - id\n",
    "    ss = np.random.SeedSequence([id, base_seed])\n",
    "    # More than 128 bits (4 32-bit words) would be overkill.\n",
    "    np.random.seed(ss.generate_state(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler(object):\n",
    "    \"\"\"Base class for all Samplers.\n",
    "    Every Sampler subclass has to provide an __iter__ method, providing a way\n",
    "    to iterate over indices of dataset elements, and a __len__ method that\n",
    "    returns the length of the returned iterators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class StratifiedSampler(Sampler):\n",
    "    \"\"\"Stratified Sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, task_vector, batch_size):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        class_vector : torch tensor\n",
    "            a vector of class labels\n",
    "        batch_size : integer\n",
    "            batch_size\n",
    "        \"\"\"\n",
    "        self.n_splits = int(task_vector.size(0) / batch_size)\n",
    "        self.task_vector = task_vector\n",
    "\n",
    "    def gen_sample_array(self):\n",
    "        try:\n",
    "            from sklearn.model_selection import StratifiedShuffleSplit\n",
    "        except:\n",
    "            print('Need scikit-learn for this functionality')\n",
    "        import numpy as np\n",
    "        \n",
    "        # s = StratifiedShuffleSplit(n_splits=self.n_splits, test_size=0.5)\n",
    "        s = StratifiedKFold(n_splits=self.n_splits, shuffle=True)\n",
    "        X = torch.randn(self.task_vector.size(0),2).numpy()\n",
    "        y = self.task_vector.numpy()\n",
    "        s.get_n_splits(X, y)\n",
    "\n",
    "        indices = []\n",
    "        for _, test_index in s.split(X, y):\n",
    "            indices = np.hstack([indices, test_index])\n",
    "        \n",
    "        # print(task_vector[indices])\n",
    "        print(indices.astype('int'))\n",
    "        indices.sort()\n",
    "        print(indices)\n",
    "\n",
    "        # train_index, test_index = next(s.split(X, y))\n",
    "        # print(task_vector[train_index])\n",
    "        # indices = np.hstack([train_index, test_index])\n",
    "        return indices.astype('int')\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.gen_sample_array())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.task_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SplitCIFARHandler([[0, 1], [8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sample_data(n=20, m=40, randomly=False)\n",
    "targets = dataset.comb_trainset.targets\n",
    "task_vector = torch.tensor([targets[i][0] for i in range(len(targets))], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "strat_sampler = StratifiedSampler(task_vector, batch_size)\n",
    "batch_sampler = torch.utils.data.BatchSampler(strat_sampler, batch_size, True)\n",
    "data_loader = DataLoader(dataset.comb_trainset, worker_init_fn=wif, pin_memory=True, num_workers=0, batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  9 13 20 24 36 38 43 48  3 11 18 25 40 42 47 54 59  8 10 17 23 29 31\n",
      " 44 45 56  0  4 12 21 22 34 50 52 55  1 15 16 28 32 37 39 49  2  7 19 27\n",
      " 33 41 51 53  6 14 26 30 35 46 57 58]\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53.\n",
      " 54. 55. 56. 57. 58. 59.]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7]\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Target Fraction : 1.000\n",
      "[8, 9, 10, 11, 12, 13, 14, 15]\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Target Fraction : 1.000\n",
      "[16, 17, 18, 19, 20, 21, 22, 23]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[24, 25, 26, 27, 28, 29, 30, 31]\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target Fraction : 0.000\n",
      "[32, 33, 34, 35, 36, 37, 38, 39]\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target Fraction : 0.000\n",
      "[40, 41, 42, 43, 44, 45, 46, 47]\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target Fraction : 0.000\n",
      "[48, 49, 50, 51, 52, 53, 54, 55]\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Target Fraction : 0.000\n"
     ]
    }
   ],
   "source": [
    "for data, targets in data_loader:\n",
    "    tasks, labels = targets\n",
    "    print(tasks)\n",
    "    print(\"Target Fraction : {:.3f}\".format(1-tasks.sum()/len(tasks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('model-zoo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57713c1868b63041d55444a5a6e7db3704257b27516ebd72764ce67cedec1dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
