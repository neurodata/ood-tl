{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ashwindesilva/research/ood-tl')\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from datahandlers.cifar import SplitCIFARHandler\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wif(id):\n",
    "    \"\"\"\n",
    "    Used to fix randomization bug for pytorch dataloader + numpy\n",
    "    Code from https://github.com/pytorch/pytorch/issues/5059\n",
    "    \"\"\"\n",
    "    process_seed = torch.initial_seed()\n",
    "    # Back out the base_seed so we can use all the bits.\n",
    "    base_seed = process_seed - id\n",
    "    ss = np.random.SeedSequence([id, base_seed])\n",
    "    # More than 128 bits (4 32-bit words) would be overkill.\n",
    "    np.random.seed(ss.generate_state(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "class Sampler(object):\n",
    "    \"\"\"Base class for all Samplers.\n",
    "    Every Sampler subclass has to provide an __iter__ method, providing a way\n",
    "    to iterate over indices of dataset elements, and a __len__ method that\n",
    "    returns the length of the returned iterators.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_source):\n",
    "        pass\n",
    "\n",
    "    def __iter__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __len__(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class StratifiedSampler(Sampler):\n",
    "    \"\"\"Stratified Sampling\n",
    "    Provides equal representation of target classes in each batch\n",
    "    \"\"\"\n",
    "    def __init__(self, task_vector, batch_size):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        class_vector : torch tensor\n",
    "            a vector of class labels\n",
    "        batch_size : integer\n",
    "            batch_size\n",
    "        \"\"\"\n",
    "        self.n_splits = int(task_vector.size(0) / batch_size)\n",
    "        self.task_vector = task_vector\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        tasks = self.task_vector.numpy()\n",
    "        self.target_indices = np.where(tasks==0)[0].tolist()\n",
    "        self.ood_indices = np.where(tasks==1)[0].tolist()\n",
    "\n",
    "    def gen_sample_array(self):\n",
    "        try:\n",
    "            from sklearn.model_selection import StratifiedShuffleSplit\n",
    "        except:\n",
    "            print('Need scikit-learn for this functionality')\n",
    "        import numpy as np\n",
    "        \n",
    "        # s = StratifiedKFold(n_splits=self.n_splits, shuffle=True)\n",
    "        # X = torch.randn(self.task_vector.size(0),2).numpy()\n",
    "        # y = self.task_vector.numpy()\n",
    "        # s.get_n_splits(X, y)\n",
    "\n",
    "        # # indices = []\n",
    "        # # for _, test_index in s.split(X, y):\n",
    "        # #     indices = np.hstack([indices, test_index])\n",
    "\n",
    "        # indices = []\n",
    "        # for i in range(self.n_splits):\n",
    "        #     _ , test_index = next(s.split(X, y))\n",
    "        #     indices = np.hstack([indices, test_index])\n",
    "\n",
    "        indices = []\n",
    "        for i in range(self.n_splits):\n",
    "            indices.extend(np.random.choice(self.target_indices, self.batch_size // 2, replace=False))\n",
    "            indices.extend(np.random.choice(self.ood_indices, self.batch_size // 2, replace=False))\n",
    "        indices = np.array(indices)\n",
    "        \n",
    "        return indices.astype('int')\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self.gen_sample_array())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.task_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SplitCIFARHandler([[0, 1], [8, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sample_data(n=20, m=100, randomly=False)\n",
    "targets = dataset.comb_trainset.targets\n",
    "task_vector = torch.tensor([targets[i][0] for i in range(len(targets))], dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "strat_sampler = StratifiedSampler(task_vector, batch_size)\n",
    "batch_sampler = torch.utils.data.BatchSampler(strat_sampler, batch_size, False)\n",
    "data_loader = DataLoader(dataset.comb_trainset, worker_init_fn=wif, pin_memory=True, num_workers=0, batch_sampler=batch_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 1, 10, 19, 37, 92, 65, 80]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[0, 10, 7, 15, 99, 100, 87, 34]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[18, 1, 7, 5, 62, 65, 107, 76]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[8, 17, 18, 2, 64, 95, 36, 35]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[2, 7, 10, 15, 36, 74, 39, 108]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[9, 3, 1, 4, 104, 65, 86, 83]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[18, 8, 14, 1, 104, 97, 82, 56]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[17, 15, 7, 3, 64, 97, 67, 79]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[16, 0, 13, 19, 113, 64, 47, 111]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[11, 6, 5, 10, 51, 86, 108, 114]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[13, 11, 5, 1, 44, 75, 24, 90]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[9, 4, 1, 15, 94, 33, 117, 59]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[2, 8, 7, 14, 55, 62, 66, 75]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[8, 14, 11, 19, 26, 55, 66, 118]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n",
      "[17, 18, 3, 8, 71, 25, 51, 98]\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "Target Fraction : 0.500\n"
     ]
    }
   ],
   "source": [
    "for data, targets in data_loader:\n",
    "    tasks, labels = targets\n",
    "    print(tasks)\n",
    "    print(\"Target Fraction : {:.3f}\".format(1-tasks.sum()/len(tasks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = task_vector.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(tasks==1)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('model-zoo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57713c1868b63041d55444a5a6e7db3704257b27516ebd72764ce67cedec1dad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
